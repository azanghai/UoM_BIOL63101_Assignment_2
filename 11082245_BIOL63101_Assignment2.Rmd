---
title: "11082245_BIOL63101_Assignment2"
author: '11082245'
date: "2022-12-15"
output: 
  rmdformats::downcute:
    self_contained: true
    thumbnails: false
    lightbox: true
    gallery: false
    toc_float: TRUE
    default_style: "dark"
    fig_caption: true
---

```{r setup, include=FALSE}
## Global options
knitr::opts_chunk$set(cache = TRUE)
```

# Before Reading

The R script, R Markdown and this `.html` file were uploaded to [my GitHub repository](https://github.com/azanghai/UoM_BIOL63101_Assignment_2), where you can view or download my code. I have also uploaded the .html file to my website. You can click [here]() to view. In order to make the code look neater, the code already explained in the text will not be explained again.

**To get the best browsing experience, maximize the browser.**

**You can use the switch button on the left if you want to switch to a different colour theme.**

------------------------------------------------------------------------

# Before start

Before starting the analysis, we want to load our packages first.

```{r, import_libraty_chunk, message=FALSE, warning=FALSE}
# load tidyverse for reading, wrangling and plotting data
library(tidyverse) 
# load afex for ANOVA functions
library(afex) 
# load emmeans for pairwise comparisons
library(emmeans) 
# load psych for data summarize 
library(psych) 
# load skimr package for data summarize
library(skimr)
# load ggpubr package for plotting
library(ggpubr)
# load car package for leveneTest
library(car)
```

# Question 1

## Load Data and Preliminary Processing

Here, by using function `read_csv()` function in `tidyverse` package, we load `.csv` file as a dataframe in RStudio.

```{r}
#load data
Q1_data = read_csv('./Raw_Data/assignment_2_dataset_1.csv')

# check if the data is correctly loaded
head(Q1_data)
```

We find that: \* value from condition needs to be renamed for better understanding. \* column `condition` needs to be converted to factor.

```{r}
# rename the value from condition_a, condition_b to normally and degraded.
# here we use mutate() function to recreate the column.
# case_when() is to select case that fits for different "condition".
Q1_data = Q1_data %>% 
    mutate(
    condition = case_when(
      condition == "condition_a" ~ "normally",
      condition == "condition_b" ~ "degraded"
    )
  )

# code condition as a factor,using mutate function and factor function to replace the old column. 
Q1_data = Q1_data %>% 
    mutate(condition = factor(condition))

# double check if the data is coded correctly.
head(Q1_data)
```

Now the data looks correctly loaded.

## Summarize the Data {.tabset .tabset-fade .tabset-pills}

Here I have use different measures to summarize the data, the result is the same, but the method provide different aspect of the data.

### Using Base R Functions

We can use base R functions to summarize the data by using following code.

```{r}
# summarize data using base R functions
Q1_data %>% 
    # we want to view the data in different conditions.
    group_by(condition) %>% 
    # here we calculate mean and sd for the data, using summarize()
    summarise(mean = mean(response_time), sd = sd(response_time))
```

### Using `psych` Package

`psych` is a package specifically coded for psychology students. It has most function for personality, psychometric theory and experimental psychology purpose. Here we use `describeBy()` function to summarize the data. The reason I use this package is because it provide values from the number of valid cases to the skew, which gives us a good understanding of the data.

```{r}
# according to the documentation of this package, to compare data in different groups, we use `describeBy()` function. 
# The first argument sent is the data frame, and the second one is the group list.
describeBy(Q1_data$response_time, Q1_data$condition)
```

### Using `skimr` Package

`skimr` is also a package that helps us summarize the data , the reason I use this package is that it can compare the data in one chart. And it's also easy to use.

```{r}
Q1_data %>% 
    group_by(condition) %>% 
    # here we use skim() function to generate summarize.
    skim() %>% 
    # as we are only interested in the response_time variable, we use filter() to select it and compare between groups.
    filter(skim_variable == "response_time")
```

## Data Visualization

Here, by visualizing the data, we can have a first impression of whether there are differences in the data.

```{r}
# Seed is set here to ensure reproducibility.
set.seed(11082245)
# use ggplot to demonstrate the distribution of data.
Q1_data %>% 
    #here we set x axis as condition, y axis as response time, and We coloured the data according to the different conditions.
    ggplot(aes(x = condition, y = response_time, colour = condition)) +
    # here we add a layer of violin plot using settings and parameters in ggplot()
    geom_violin() +
    # let the dots jitter a little bit to have a better look.
    geom_jitter(width = .1) +
    # the figure is clear enough and we do not need a guides.
    guides(colour = FALSE) +
    # here we use stat_summary() function to add another layer. 
    # "mean_cl_boot" is a built in function to acquire confidence limits for the mean.
    stat_summary(fun.data = "mean_cl_boot", colour = "black") +
    # also, a theme and text size is set here for a better view.
    theme_minimal() +
    theme(text = element_text(size = 13)) 
```

By viewing the plot, we have also found that there is no abnormal value. So we don't need to remove the abnormal value

## Normality and Homogeneity of Variance Test

As there are three assumptions in ANOVA.\
- The responses for each factor level have a normal population distribution.\
- These distributions have the same variance.\
- The data are independent.

Though the program will calculate and correct the variance, and The central limit theorem tells us that no matter what distribution things have, the sampling distribution tends to be normal if the sample is large enough (n \> 30). Still, we would like to perform a test for Normal Distribution and Homogeneity of Variance

### Normality Test {.tabset .tabset-fade .tabset-pills}

#### Q-Q plot

We can draw a Q-Q plot to find whether the data is distributed normally.

As we can see, if the dots is distributed around the line `y = x`, it means that the distribution of the data is likely to be Normal distribution. But to be certain, we also need to perform a Normal Distribution Test

```{r}
ggplot(data = Q1_data, aes(sample = response_time, colour = factor(condition))) +
  geom_qq() +
  geom_qq_line() +
  facet_wrap(~condition) +
  guides(colour = FALSE) +
  labs(y = "Response Time", x = "Normal Theoretical Quantiles") +
  theme_minimal() +
  theme(text = element_text(size = 13))
```

From the plot, we can see that the dots for different data group is closely attached to the `y = x` line. Therefore, the data may be normally distributed.

#### Shapiro-Wilk Normality Test

Then we perform a Shapiro-Wilk normality test.

```{r}
# here we use tapply()function, the first argument is the data frame, the second argument is the Classification parameters, the third one is the function that we want to perform, this function allows us to perform multiple repeated functions by using one line of code.
tapply(Q1_data$response_time,Q1_data$condition,shapiro.test)
```

For the output, the P-value \> 0.05. Therefore we could say that the distribution of the data are not significantly different from normal distribution. In other words, we can assume the normality.

### Homogeneity of Variance Test

Here we perform a Levene's Test for Homogeneity of Variance. Only because this is one of the most commonly used method.

```{r}
# this function is in car package which is loaded by the tidyverse. Just like the liner model, we load the factor and the variable in the function to get a result
leveneTest(response_time ~ condition, data = Q1_data)
```

As the p-value is higher than 0.05(0.5175), Therefore we accept the null hypothesis (H0): the variances of the two groups are equal.

## Building ANOVA model

Here, we build the model by considering `response_time` as DV, and `condition` as IV. Meanwhile, `participant` is considered as the souce of random error.

```{r}
Q1_model_1 = aov_4(response_time ~ condition + (1 | participant),data = Q1_data)
```

Then, we would like to take a look at the model we built, and perform a post-hoc analysis.

```{r}
summary(Q1_model_1)
# by using emmeans(), we could compare the data group by the condition factor. 
emmeans(Q1_model_1, pairwise~condition)
```

we can also view the result in a plot by adding sever layer on the plot we have made. Function `stat_compare_means()` is used to accomplish this task. By setting `comparisons` to `degraded` and `normally`, we draw a line to indicate the p-value between these groups. Also, by setting `symnum.args`, we can convert p-value to symbols for a better understanding.

```{r,warning=FALSE,message = FALSE,results='hide'}
Q1_data %>%
    ggplot(aes(x = condition, y = response_time, colour = condition)) +
    geom_violin() +
    geom_jitter(width = .1) +
    # here we add ANOVA result to the plot
    stat_compare_means(method = "anova") + 
    # here we draw the line to compare groups
    stat_compare_means(comparisons = list(c("degraded", "normally")),symnum.args = list(
        # use * to illustrate the p value
        cutpoints = c(0, 0.0001, 0.001, 0.01, 0.05, Inf),
        symbols = c("****", "***", "**", "*", "ns")
    )) +
    guides(colour = FALSE)+
    theme_minimal() +
    theme(text = element_text(size = 13))+
    labs(y = "Response Time", x = "Conditions")
```

### T-test

As the experiment is a between participants design, and only have a factor with 2 levels. Therefore, a t-test is available for the data analysis.

```{r}
# by using built in t.test() function, the first parameter we sent is the data frame, and the second one is group value, the function will perform a t-test based on the parameter we sent.
t.test(Q1_data$response_time ~ Q1_data$condition)
```

The result is similar, difference is significant.

## Conclusion

From the analysis performed. It can be inferred that the difference between response time caused by different visual quality is significant. Which means, the subject will response quicker(estimated marginal means = 1002) with normally present the words than visually degraded(estimated marginal means = 1020).

# Question 2

## Load Data and Preliminary Processing

Similiar to Question 1, we want to load the data and perform some preliminary processing.

```{r}
Q2_data = read_csv('./Raw_Data/assignment_2_dataset_2.csv')
head(Q2_data)

Q2_data = Q2_data %>% 
    mutate(
    condition = case_when(
      condition == "condition_a" ~ "normally",
      condition == "condition_b" ~ "degraded"
    )
  )
head(Q2_data)
```

Also, we want to convert `condition` in to factor.

```{r}
Q2_data = Q2_data %>% 
    mutate(condition = factor(condition))
head(Q2_data)
```

## Summarize the Data

Here, we use `skimr` package to summarize the data. In this case, we want to learn the distribution of the data under the condition `caffeine` and `condition`.

```{r}
Q2_data %>% 
    group_by(condition) %>% 
    skim() %>% 
    filter(skim_variable != "participant")

Q2_data %>% 
    group_by(caffeine) %>% 
    skim() %>% 
    filter(skim_variable == "response_time")
```

However, this is still to complicated. Data visualization is considered to demonstrate the data in a more efficient way.

## Data Visualization

Here, we built a scatter plot. By viewing the plot, it seems that there is a relation between response time and caffeine consumption.

```{r}
# we set colour = condition in order to distinguish the relation between caffeine consumption and conditions. 
ggplot(Q2_data, aes(x = caffeine, y = response_time, colour = condition)) + 
    geom_point(size = 3, alpha = .9) +
    labs(x = "Caffeine Consumption (cups of coffee)", 
         y = "Response Time") +
    theme_minimal() +
    theme(text = element_text(size = 11)) 
```

Again, as the data is identical to question 1, we do not need to repeat the normality and homogeneity of variance test, nor do we need to remove any abnormal data.

## Building Model {.tabset .tabset-fade .tabset-pills}

### ANOVA Model

In this case, we set `response` as DV, and condition as IV. Also, we add caffeine as a covariate. Meanwhile, we set `factorize` as false to avoid program reading `caffeine` as a factor.

```{r}
Q2_model = aov_4(response_time ~ caffeine + condition +(1 | participant),data = Q2_data,factorize = FALSE)
```

After that we use `anova()` function to acquire the effect size. And using `emmeans` to compare different groups.

```{r}
anova(Q2_model)
# here we use 'pairwise' to compare different conditions
emmeans(Q2_model, pairwise ~ condition)
```

From the result, it seems that the effect of covariate and conditions is not significant in this case. And the adjusted means is slightly different when considering the influence of caffeine(normally from 1002 to 1005, degraded from 1020 to 1018).

### linear model

Here, we use the `lm()` function to build a linear model. But first,we want to set the factor level.

```{r}
Q2_data <- Q2_data %>%
    mutate(condition = fct_relevel(condition,
                                   c("normally","degraded")))
# here we use contrasts() to check the contrasts
contrasts(Q2_data$condition)
```

We are doing this because this will set `normally` as the intercept.

```{r}
Q2_model_lm = lm(response_time ~ condition + caffeine, data = Q2_data)
Q2_model_lm
```

At this step we can finally write the function as `Resopnse Time = 998.564 + 12.791*degraded + 2.469*mean(Q2_data$caffeine)`. Therefor we can compare the result with ANOVA result.

```{r}
# for ANOVA result: normally = 1005
Resopnse_Time_normally = 998.564 + 12.791*0 + 2.469*mean(Q2_data$caffeine)
Resopnse_Time_normally

# for ANOVA result: degraded = 1018
Resopnse_Time_degraded = 998.564 + 12.791*1 + 2.469*mean(Q2_data$caffeine)
Resopnse_Time_degraded
```

As we can see, the result is rounded to the ANOVA result. That means they have the same result.

However, it seems to me that there is no clear "order" between the two levels under condition, they are just different categories. So it is a little bit "weird" to use "normally" as an intercept. To solve this feeling, I find a way to set the intercept to zero.

```{r}
Q2_model_lm_1 = lm(response_time ~ condition - 1 + caffeine, data = Q2_data)
Q2_model_lm_1
```

I find this method on [stack overflow](https://stackoverflow.com/questions/41032858/lm-summary-not-display-all-factor-levels), It seems that the `-1` change the order of the factor level.

Also, there is another way to add a `0` in the formula. This sets the intercept to zero.

```{r}
Q2_model_lm_2 = lm(response_time ~ 0 + caffeine + condition, data = Q2_data)
Q2_model_lm_2
```

